{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from PyPDF2 import PdfReader\n",
    "import openai\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bitcoin: A Peer-to-Peer Electronic Cash System\\nSatoshi Nakamoto\\nsatoshin@gmx.com\\nwww.bitcoin.org\\nAbstract.  A purely peer-to-peer version of electronic cash would allow online  \\npayments to be sent directly from one party to another without going through a  \\nfinancial institution.  Digital signatures provide part of the solution, but the main  \\nbenefits are lost if a trusted third party is still required to prevent double-spending.  \\nWe propose a solution to the double-spending problem using a peer-to-peer network.  \\nThe network timestamps transactions by hashing them into an ongoing chain of  \\nhash-based proof-of-work, forming a record that cannot be changed without redoing  \\nthe proof-of-work.  The longest chain not only serves as proof of the sequence of  \\nevents witnessed, but proof that it came from the largest pool of CPU power.  As  \\nlong as a majority of CPU power is controlled by nodes that are not cooperating to  \\nattack the network, they\\'ll generate the longest chain and outpace attackers.  The  \\nnetwork itself requires minimal structure.  Messages are broadcast on a best effort  \\nbasis, and nodes can leave and rejoin the network at will, accepting the longest  \\nproof-of-work chain as proof of what happened while they were gone.\\n1.Introduction\\nCommerce on the Internet has come to rely almost exclusively on financial institutions serving as  \\ntrusted third parties to process electronic payments.  While the system works well enough for  \\nmost  transactions,  it  still  suffers  from  the  inherent  weaknesses  of  the  trust  based  model.  \\nCompletely non-reversible transactions are not really possible, since financial institutions cannot  \\navoid  mediating  disputes.   The  cost  of  mediation  increases  transaction  costs,  limiting  the  \\nminimum practical transaction size and cutting off the possibility for small casual transactions,  \\nand there is a broader cost in the loss of ability to make non-reversible payments for non-\\nreversible services.  With the possibility of reversal, the need for trust spreads.  Merchants must  \\nbe wary of their customers, hassling them for more information than they would otherwise need.  \\nA certain percentage of fraud is accepted as unavoidable.  These costs and payment uncertainties  \\ncan be avoided in person by using physical currency, but no mechanism exists to make payments  \\nover a communications channel without a trusted party.\\nWhat is needed is an electronic payment system based on cryptographic proof instead of trust,  \\nallowing any two willing parties to transact directly with each other without the need for a trusted  \\nthird party.  Transactions that are computationally impractical to reverse would protect sellers  \\nfrom fraud, and routine escrow mechanisms could easily be implemented to protect buyers.  In  \\nthis paper, we propose a solution to the double-spending problem using a peer-to-peer distributed  \\ntimestamp server to generate computational proof of the chronological order of transactions.  The  \\nsystem  is  secure  as  long  as  honest  nodes  collectively  control  more  CPU  power  than  any  \\ncooperating group of attacker nodes.\\n12.Transactions\\nWe define an electronic coin as a chain of digital signatures.  Each owner transfers the coin to the  \\nnext by digitally signing a hash of the previous transaction and the public key of the next owner  \\nand adding these to the end of the coin.  A payee can verify the signatures to verify the chain of  \\nownership.\\nThe problem of course is the payee can\\'t verify that one of the owners did not double-spend  \\nthe coin.  A common solution is to introduce a trusted central authority, or mint, that checks every  \\ntransaction for double spending.  After each transaction, the coin must be returned to the mint to  \\nissue a new coin, and only coins issued directly from the mint are trusted not to be double-spent.  \\nThe problem with this solution is that the fate of the entire money system depends on the  \\ncompany running the mint, with every transaction having to go through them, just like a bank.\\nWe need a way for the payee to know that the previous owners did not sign any earlier  \\ntransactions.  For our purposes, the earliest transaction is the one that counts, so we don\\'t care  \\nabout later attempts to double-spend.  The only way to confirm the absence of a transaction is to  \\nbe aware of all transactions.  In the mint based model, the mint was aware of all transactions and  \\ndecided which arrived first.  To accomplish this without a trusted party, transactions must be  \\npublicly announced [1], and we need a system for participants to agree on a single history of the  \\norder in which they were received.  The payee needs proof that at the time of each transaction, the  \\nmajority of nodes agreed it was the first received. \\n3.Timestamp Server\\nThe solution we propose begins with a timestamp server.  A timestamp server works by taking a  \\nhash  of a block of items  to  be timestamped  and  widely publishing  the hash,  such as  in  a  \\nnewspaper or Usenet post [2-5].  The timestamp proves that the data must have existed at the  \\ntime, obviously, in order to get into the hash.  Each timestamp includes the previous timestamp in  \\nits hash, forming a chain, with each additional timestamp reinforcing the ones before it.\\n2Block\\nItemItem...Hash\\nBlock\\nItemItem...HashTransaction\\nOwner 1\\'sPublic Key\\nOwner 0\\'sSignatureHashTransaction\\nOwner 2\\'sPublic Key\\nOwner 1\\'sSignatureHash\\n VerifyTransaction\\nOwner 3\\'sPublic Key\\nOwner 2\\'sSignatureHash\\n Verify\\nOwner 2\\'sPrivate KeyOwner 1\\'sPrivate KeySign  Sign  \\nOwner 3\\'sPrivate Key4.Proof-of-Work\\nTo implement a distributed timestamp server on a peer-to-peer basis, we will need to use a proof-\\nof-work system similar to Adam Back\\'s Hashcash [6], rather than newspaper or Usenet posts.  \\nThe proof-of-work involves scanning for a value that when hashed, such as with SHA-256, the  \\nhash begins with a number of zero bits.  The average work required is exponential in the number  \\nof zero bits required and can be verified by executing a single hash.\\nFor our timestamp network, we implement the proof-of-work by incrementing a nonce in the  \\nblock until a value is found that gives the block\\'s hash the required zero bits.  Once the CPU  \\neffort has been expended to make it satisfy the proof-of-work, the block cannot be changed  \\nwithout redoing the work.  As later blocks are chained after it, the work to change the block  \\nwould include redoing all the blocks after it.\\nThe proof-of-work also solves the problem of determining representation in majority decision  \\nmaking.  If the majority were based on one-IP-address-one-vote, it could be subverted by anyone  \\nable  to  allocate  many  IPs.   Proof-of-work  is  essentially  one-CPU-one-vote.   The  majority  \\ndecision is represented by the longest chain, which has the greatest proof-of-work effort invested  \\nin it.  If a majority of CPU power is controlled by honest nodes, the honest chain will grow the  \\nfastest and outpace any competing chains.  To modify a past block, an attacker would have to  \\nredo the proof-of-work of the block and all blocks after it and then catch up with and surpass the  \\nwork of the honest nodes.  We will show later that the probability of a slower attacker catching up  \\ndiminishes exponentially as subsequent blocks are added.\\nTo compensate for increasing hardware speed and varying interest in running nodes over time,  \\nthe proof-of-work difficulty is determined by a moving average targeting an average number of  \\nblocks per hour.  If they\\'re generated too fast, the difficulty increases.\\n5.Network\\nThe steps to run the network are as follows:\\n1)New transactions are broadcast to all nodes.\\n2)Each node collects new transactions into a block.  \\n3)Each node works on finding a difficult proof-of-work for its block.\\n4)When a node finds a proof-of-work, it broadcasts the block to all nodes.\\n5)Nodes accept the block only if all transactions in it are valid and not already spent.\\n6)Nodes express their acceptance of the block by working on creating the next block in the  \\nchain, using the hash of the accepted block as the previous hash.\\nNodes always consider the longest chain to be the correct one and will keep working on  \\nextending it.  If two nodes broadcast different versions of the next block simultaneously, some  \\nnodes may receive one or the other first.  In that case, they work on the first one they received,  \\nbut save the other branch in case it becomes longer.  The tie will be broken when the next proof-\\nof-work is found and one branch becomes longer; the nodes that were working on the other  \\nbranch will then switch to the longer one.\\n3Block\\nPrev HashNonce\\nTxTx...Block\\nPrev HashNonce\\nTxTx...New transaction broadcasts do not necessarily need to reach all nodes.  As long as they reach  \\nmany nodes, they will get into a block before long.  Block broadcasts are also tolerant of dropped  \\nmessages.  If a node does not receive a block, it will request it when it receives the next block and  \\nrealizes it missed one.\\n6.Incentive\\nBy convention, the first transaction in a block is a special transaction that starts a new coin owned  \\nby the creator of the block.  This adds an incentive for nodes to support the network, and provides  \\na way to initially distribute coins into circulation, since there is no central authority to issue them.  \\nThe steady addition of a constant of amount of new coins is analogous to gold miners expending  \\nresources to add gold to circulation.  In our case, it is CPU time and electricity that is expended.\\nThe incentive can also be funded with transaction fees.  If the output value of a transaction is  \\nless than its input value, the difference is a transaction fee that is added to the incentive value of  \\nthe block  containing  the transaction.   Once  a  predetermined number of coins  have  entered  \\ncirculation, the incentive can transition entirely to transaction fees and be completely inflation  \\nfree.\\nThe incentive may help encourage nodes to stay honest.  If a greedy attacker is able to  \\nassemble more CPU power than all the honest nodes, he would have to choose between using it  \\nto defraud people by stealing back his payments, or using it to generate new coins.  He ought to  \\nfind it more profitable to play by the rules, such rules that favour him with more new coins than  \\neveryone else combined, than to undermine the system and the validity of his own wealth.\\n7.Reclaiming Disk Space\\nOnce the latest transaction in a coin is buried under enough blocks, the spent transactions before  \\nit can be discarded to save disk space.  To facilitate this without breaking the block\\'s hash,  \\ntransactions are hashed in a Merkle Tree [7][2][5], with only the root included in the block\\'s hash.  \\nOld blocks can then be compacted by stubbing off branches of the tree.  The interior hashes do  \\nnot need to be stored.\\nA block header with no transactions would be about 80 bytes.  If we suppose blocks are  \\ngenerated every 10 minutes, 80 bytes * 6 * 24 * 365 = 4.2MB per year.  With computer systems  \\ntypically selling with 2GB of RAM as of 2008, and Moore\\'s Law predicting current growth of  \\n1.2GB per year, storage should not be a problem even if the block headers must be kept in  \\nmemory.\\n4Block BlockBlock Header (Block Hash)\\nPrev HashNonce\\nHash01\\nHash0Hash1Hash2Hash3Hash23Root Hash\\nHash01\\nHash2\\nTx3Hash23Block Header (Block Hash)\\nRoot Hash\\nTransactions Hashed in a Merkle Tree After Pruning Tx0-2 from the BlockPrev HashNonce\\nHash3\\nTx0Tx1Tx2Tx38.Simplified Payment Verification\\nIt is possible to verify payments without running a full network node.  A user only needs to keep  \\na copy of the block headers of the longest proof-of-work chain, which he can get by querying  \\nnetwork nodes until he\\'s convinced he has the longest chain, and obtain the Merkle branch  \\nlinking the transaction to the block it\\'s timestamped in.  He can\\'t check the transaction for  \\nhimself, but by linking it to a place in the chain, he can see that a network node has accepted it,  \\nand blocks added after it further confirm the network has accepted it.\\nAs such, the verification is reliable as long as honest nodes control the network, but is more  \\nvulnerable if the network is overpowered by an attacker.  While network nodes can verify  \\ntransactions for themselves, the simplified method can be fooled by an attacker\\'s fabricated  \\ntransactions for as long as the attacker can continue to overpower the network.  One strategy to  \\nprotect against this would be to accept alerts from network nodes when they detect an invalid  \\nblock, prompting the user\\'s  software to download the full  block and alerted transactions to  \\nconfirm the inconsistency.  Businesses that receive frequent payments will probably still want to  \\nrun their own nodes for more independent security and quicker verification.\\n9.Combining and Splitting Value\\nAlthough it would be possible to handle coins individually, it would be unwieldy to make a  \\nseparate transaction for every cent in a transfer.  To allow value to be split and combined,  \\ntransactions contain multiple inputs and outputs.  Normally there will be either a single input  \\nfrom a larger previous transaction or multiple inputs combining smaller amounts, and at most two  \\noutputs: one for the payment, and one returning the change, if any, back to the sender.  \\nIt should be noted that fan-out, where a transaction depends on several transactions, and those  \\ntransactions depend on many more, is not a problem here.  There is never the need to extract a  \\ncomplete standalone copy of a transaction\\'s history.\\n5Transaction\\nIn\\n...InOut\\n...Hash01\\nHash2Hash3Hash23Block Header\\nMerkle RootPrev HashNonceBlock Header\\nMerkle RootPrev HashNonceBlock Header\\nMerkle RootPrev HashNonce\\nMerkle Branch for Tx3Longest Proof-of-Work Chain\\nTx310.Privacy\\nThe traditional banking model achieves a level of privacy by limiting access to information to the  \\nparties involved and the trusted third party.  The necessity to announce all transactions publicly  \\nprecludes this method, but privacy can still be maintained by breaking the flow of information in  \\nanother place: by keeping public keys anonymous.  The public can see that someone is sending  \\nan amount to someone else, but without information linking the transaction to anyone.  This is  \\nsimilar to the level of information released by stock exchanges, where the time and size of  \\nindividual trades, the \"tape\", is made public, but without telling who the parties were.\\nAs an additional firewall, a new key pair should be used for each transaction to keep them  \\nfrom being linked to a common owner.  Some linking is still unavoidable with multi-input  \\ntransactions, which necessarily reveal that their inputs were owned by the same owner.  The risk  \\nis that if the owner of a key is revealed, linking could reveal other transactions that belonged to  \\nthe same owner.\\n11.Calculations\\nWe consider the scenario of an attacker trying to generate an alternate chain faster than the honest  \\nchain.  Even if this is accomplished, it does not throw the system open to arbitrary changes, such  \\nas creating value out of thin air or taking money that never belonged to the attacker.  Nodes are  \\nnot going to accept an invalid transaction as payment, and honest nodes will never accept a block  \\ncontaining them.  An attacker can only try to change one of his own transactions to take back  \\nmoney he recently spent.\\nThe race between the honest chain and an attacker chain can be characterized as a Binomial  \\nRandom Walk.  The success event is the honest chain being extended by one block, increasing its  \\nlead by +1, and the failure event is the attacker\\'s chain being extended by one block, reducing the  \\ngap by -1.\\nThe probability of an attacker catching up from a given deficit is analogous to a Gambler\\'s  \\nRuin problem.  Suppose a gambler with unlimited credit starts at a deficit and plays potentially an  \\ninfinite number of trials to try to reach breakeven.  We can calculate the probability he ever  \\nreaches breakeven, or that an attacker ever catches up with the honest chain, as follows [8]:\\np = probability an honest node finds the next block\\nq = probability the attacker finds the next block\\nqz = probability the attacker will ever catch up from z blocks behind\\nqz={1ifp≤q\\n\\ue09eq/p\\ue09fzifp\\ue085q}\\n6IdentitiesTransactionsTrustedThird PartyCounterpartyPublic\\nIdentitiesTransactionsPublicNew Privacy ModelTraditional Privacy ModelGiven our assumption that p > q, the probability drops exponentially as the number of blocks the  \\nattacker has to catch up with increases.  With the odds against him, if he doesn\\'t make a lucky  \\nlunge forward early on, his chances become vanishingly small as he falls further behind.\\nWe now consider how long the recipient of a new transaction needs to wait before being  \\nsufficiently certain the sender can\\'t change the transaction.  We assume the sender is an attacker  \\nwho wants to make the recipient believe he paid him for a while, then switch it to pay back to  \\nhimself after some time has passed.  The receiver will be alerted when that happens, but the  \\nsender hopes it will be too late.\\nThe receiver generates a new key pair and gives the public key to the sender shortly before  \\nsigning.  This prevents the sender from preparing a chain of blocks ahead of time by working on  \\nit continuously until he is lucky enough to get far enough ahead, then executing the transaction at  \\nthat moment.  Once the transaction is sent, the dishonest sender starts working in secret on a  \\nparallel chain containing an alternate version of his transaction.\\nThe recipient waits until the transaction has been added to a block and z blocks have been \\nlinked after it.   He doesn\\'t  know the exact amount of progress  the attacker has  made, but  \\nassuming the honest blocks took the average expected time per block, the attacker\\'s potential  \\nprogress will be a Poisson distribution with expected value:\\n\\ue0c1=zq\\np\\nTo get the probability the attacker could still catch up now, we multiply the Poisson density for  \\neach amount of progress he could have made by the probability he could catch up from that point:\\n∑k=0∞\\ue0c1ke−\\ue0c1\\nk!⋅{\\ue09eq/p\\ue09f\\ue09ez−k\\ue09fifk≤z\\n1ifk\\ue085z}\\nRearranging to avoid summing the infinite tail of the distribution...\\n1−∑k=0z\\ue0c1ke−\\ue0c1\\nk!\\ue09e1−\\ue09eq/p\\ue09f\\ue09ez−k\\ue09f\\ue09f\\nConverting to C code...\\n#include <math.h>double AttackerSuccessProbability(double q, int z){    double p = 1.0 - q;    double lambda = z * (q / p);    double sum = 1.0;    int i, k;    for (k = 0; k <= z; k++)    {        double poisson = exp(-lambda);        for (i = 1; i <= k; i++)            poisson *= lambda / i;        sum -= poisson * (1 - pow(q / p, z - k));    }    return sum;}\\n7Running some results, we can see the probability drop off exponentially with z.\\nq=0.1z=0    P=1.0000000z=1    P=0.2045873z=2    P=0.0509779z=3    P=0.0131722z=4    P=0.0034552z=5    P=0.0009137z=6    P=0.0002428z=7    P=0.0000647z=8    P=0.0000173z=9    P=0.0000046z=10   P=0.0000012\\nq=0.3z=0    P=1.0000000z=5    P=0.1773523z=10   P=0.0416605z=15   P=0.0101008z=20   P=0.0024804z=25   P=0.0006132z=30   P=0.0001522z=35   P=0.0000379z=40   P=0.0000095z=45   P=0.0000024z=50   P=0.0000006\\nSolving for P less than 0.1%...\\nP < 0.001q=0.10   z=5q=0.15   z=8q=0.20   z=11q=0.25   z=15q=0.30   z=24q=0.35   z=41q=0.40   z=89q=0.45   z=340\\n12.Conclusion\\nWe have proposed a system for electronic transactions without relying on trust.  We started with  \\nthe usual framework of coins made from digital signatures, which provides strong control of  \\nownership, but is incomplete without a way to prevent double-spending.  To solve this, we  \\nproposed a peer-to-peer network using proof-of-work to record a public history of transactions  \\nthat quickly becomes computationally impractical for an attacker to change if honest nodes  \\ncontrol a majority of CPU power.  The network is robust in its unstructured simplicity.  Nodes  \\nwork all at once with little coordination.  They do not need to be identified, since messages are  \\nnot routed to any particular place and only need to be delivered on a best effort basis.  Nodes can  \\nleave  and  rejoin  the  network  at  will,  accepting  the  proof-of-work  chain  as  proof  of  what  \\nhappened while they were gone.  They vote with their CPU power, expressing their acceptance of  \\nvalid blocks by working on extending them and rejecting invalid blocks by refusing to work on  \\nthem.  Any needed rules and incentives can be enforced with this consensus mechanism.\\n8References\\n[1]W. Dai, \"b-money,\" http://www.weidai.com/bmoney.txt, 1998.\\n[2]H. Massias, X.S. Avila, and J.-J. Quisquater, \"Design of a secure timestamping service with minimal  \\ntrust requirements,\" In 20th Symposium on Information Theory in the Benelux , May 1999.\\n[3]S. Haber, W.S. Stornetta, \"How to time-stamp a digital document,\" In Journal of Cryptology, vol 3, no \\n2, pages 99-111, 1991.\\n[4]D. Bayer, S. Haber, W.S. Stornetta, \"Improving the efficiency and reliability of digital time-stamping,\"  \\nIn Sequences II: Methods in Communication, Security and Computer Science , pages 329-334, 1993.\\n[5]S. Haber, W.S. Stornetta, \"Secure names for bit-strings,\" In Proceedings of the 4th ACM Conference  \\non Computer and Communications Security , pages 28-35, April 1997.\\n[6]A. Back, \"Hashcash - a denial of service counter-measure,\"  \\nhttp://www.hashcash.org/papers/hashcash.pdf, 2002.\\n[7]R.C. Merkle, \"Protocols for public key cryptosystems,\" In Proc. 1980 Symposium on Security and \\nPrivacy, IEEE Computer Society, pages 122-133, April 1980.\\n[8]W. Feller, \"An introduction to probability theory and its applications,\" 1957.\\n9'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_url = \"https://bitcoin.org/bitcoin.pdf\"\n",
    "\n",
    "def get_pdf_object(url):\n",
    "    response = requests.get(arxiv_url)\n",
    "    reader = PdfReader(BytesIO(response.content))\n",
    "    return reader\n",
    "\n",
    "def get_pdf_text(url):\n",
    "    response = requests.get(arxiv_url)\n",
    "    reader = PdfReader(BytesIO(response.content))\n",
    "    corpus = ''\n",
    "    for i in reader.pages:\n",
    "        corpus += i.extract_text()\n",
    "    # remove newlines\n",
    "    # corpus = corpus.replace(\"\\x03\", \"\").replace(\"\\n\", \"\")\n",
    "    return corpus\n",
    "\n",
    "corpus = get_pdf_text(arxiv_url)\n",
    "pdf = get_pdf_object(arxiv_url)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_paper(pdf):\n",
    "  print(\"Parsing paper\")\n",
    "  number_of_pages = len(pdf.pages)\n",
    "  print(f\"Total number of pages: {number_of_pages}\")\n",
    "  paper_text = []\n",
    "  for i in range(number_of_pages):\n",
    "    page = pdf.pages[i]\n",
    "    page_text = []\n",
    "\n",
    "    def visitor_body(text, cm, tm, fontDict, fontSize):\n",
    "      x = tm[4]\n",
    "      y = tm[5]\n",
    "      # ignore header/footer\n",
    "      if (y > 50 and y < 720) and (len(text.strip()) > 1):\n",
    "        page_text.append({\n",
    "          'fontsize': fontSize,\n",
    "          'text': text.strip().replace('\\x03', ''),\n",
    "          'x': x,\n",
    "          'y': y\n",
    "        })\n",
    "\n",
    "    _ = page.extract_text(visitor_text=visitor_body)\n",
    "\n",
    "    blob_font_size = None\n",
    "    blob_text = ''\n",
    "    processed_text = []\n",
    "\n",
    "    for t in page_text:\n",
    "      if t['fontsize'] == blob_font_size:\n",
    "        blob_text += f\" {t['text']}\"\n",
    "      else:\n",
    "        if blob_font_size is not None and len(blob_text) > 1:\n",
    "          processed_text.append({\n",
    "            'fontsize': blob_font_size,\n",
    "            'text': blob_text,\n",
    "            'page': i\n",
    "          })\n",
    "        blob_font_size = t['fontsize']\n",
    "        blob_text = t['text']\n",
    "    paper_text += processed_text\n",
    "  return paper_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing paper\n",
      "Total number of pages: 9\n"
     ]
    }
   ],
   "source": [
    "paper = parse_paper(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_df(pdf):\n",
    "    filtered_pdf= []\n",
    "    for row in pdf:\n",
    "        if len(row['text']) < 30:\n",
    "            continue\n",
    "        filtered_pdf.append(row)\n",
    "    df = pd.DataFrame(filtered_pdf)\n",
    "    df['length'] = df['text'].apply(lambda x: len(x))\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = paper_df(paper)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embeddings(df):\n",
    "    embedding_model = \"text-embedding-ada-002\"\n",
    "    embeddings = df.text.apply([lambda x: get_embedding(x, engine=embedding_model)])\n",
    "    df[\"embeddings\"] = embeddings\n",
    "    return df\n",
    "\n",
    "calculate_embeddings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_reviews(df, query, n=3, pprint=True):\n",
    "    query_embedding = get_embedding(\n",
    "        query,\n",
    "        engine=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    df[\"similarity\"] = df.embeddings.apply(lambda x: cosine_similarity(x, query_embedding))\n",
    "\n",
    "    results = (\n",
    "        df.sort_values(\"similarity\", ascending=False, ignore_index=True)\n",
    "        \n",
    "    )\n",
    "    return results.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fontsize</th>\n",
       "      <th>text</th>\n",
       "      <th>page</th>\n",
       "      <th>length</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Common Errors Cheat Sheet Students frequently ...</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>[-0.007276198361068964, 0.03181527554988861, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Incorrect: Many red foxes live here. The noctu...</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>[0.01625715009868145, -0.0023440392687916756, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>so that we can coexist. Incomplete and run on ...</td>\n",
       "      <td>1</td>\n",
       "      <td>375</td>\n",
       "      <td>[0.0050130984745919704, 0.003571423003450036, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Passive: The pasta was eat en by Josephine. Ac...</td>\n",
       "      <td>2</td>\n",
       "      <td>328</td>\n",
       "      <td>[-0.004926593974232674, -0.0034326203167438507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>it unclearly; the word could refer to article ...</td>\n",
       "      <td>2</td>\n",
       "      <td>352</td>\n",
       "      <td>[0.0018352309707552195, 0.000923340383451432, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  fontsize                                               text  \\\n",
       "0           0       1.0  Common Errors Cheat Sheet Students frequently ...   \n",
       "1           7       1.0  Incorrect: Many red foxes live here. The noctu...   \n",
       "2          18       1.0  so that we can coexist. Incomplete and run on ...   \n",
       "3          23       1.0  Passive: The pasta was eat en by Josephine. Ac...   \n",
       "4          42       1.0  it unclearly; the word could refer to article ...   \n",
       "\n",
       "   page  length                                         embeddings  \n",
       "0     0     314  [-0.007276198361068964, 0.03181527554988861, 0...  \n",
       "1     1     307  [0.01625715009868145, -0.0023440392687916756, ...  \n",
       "2     1     375  [0.0050130984745919704, 0.003571423003450036, ...  \n",
       "3     2     328  [-0.004926593974232674, -0.0034326203167438507...  \n",
       "4     2     352  [0.0018352309707552195, 0.000923340383451432, ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"embeddings.csv\")\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = test.drop_duplicates(subset=['text', 'page'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fontsize</th>\n",
       "      <th>text</th>\n",
       "      <th>page</th>\n",
       "      <th>length</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Common Errors Cheat Sheet Students frequently ...</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>[-0.007217978592962027, 0.03192491456866264, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Incorrect: Many red foxes live here. The noctu...</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>[0.016169091686606407, -0.0023459333460778, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>so that we can coexist. Incomplete and run on ...</td>\n",
       "      <td>1</td>\n",
       "      <td>375</td>\n",
       "      <td>[0.005041639320552349, 0.0035730735398828983, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Passive: The pasta was eat en by Josephine. Ac...</td>\n",
       "      <td>2</td>\n",
       "      <td>328</td>\n",
       "      <td>[-0.004948729649186134, -0.0033812588080763817...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>it unclearly; the word could refer to article ...</td>\n",
       "      <td>2</td>\n",
       "      <td>352</td>\n",
       "      <td>[0.0018352309707552195, 0.000923340383451432, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>He assured me that the work had been completed...</td>\n",
       "      <td>3</td>\n",
       "      <td>307</td>\n",
       "      <td>[0.009392737410962582, -0.010591392405331135, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Impact affect, and effect Impact is a percussi...</td>\n",
       "      <td>4</td>\n",
       "      <td>317</td>\n",
       "      <td>[-0.024574613198637962, 0.0024615300353616476,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>affect versus effect Affect is the verb and ef...</td>\n",
       "      <td>4</td>\n",
       "      <td>323</td>\n",
       "      <td>[-0.01929573528468609, 0.009030453860759735, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Who and that. Use who to refer to a person; us...</td>\n",
       "      <td>5</td>\n",
       "      <td>309</td>\n",
       "      <td>[-0.00878846738487482, 0.008603863418102264, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>If you join two complete sentences with a comm...</td>\n",
       "      <td>6</td>\n",
       "      <td>302</td>\n",
       "      <td>[-0.0018168585374951363, 0.0324668250977993, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>per five pages of text is a good limit; h owev...</td>\n",
       "      <td>6</td>\n",
       "      <td>325</td>\n",
       "      <td>[-0.015518540516495705, 0.008858335204422474, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dash if you type two hyphens in a row, without...</td>\n",
       "      <td>6</td>\n",
       "      <td>326</td>\n",
       "      <td>[-0.008831623941659927, -0.0022563396487385035...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Awkward: The sensor measures senescence (veget...</td>\n",
       "      <td>7</td>\n",
       "      <td>302</td>\n",
       "      <td>[-0.008791771717369556, -0.005126894451677799,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>around articles ; italicize publications In bo...</td>\n",
       "      <td>7</td>\n",
       "      <td>303</td>\n",
       "      <td>[-0.010349431075155735, 0.011574254371225834, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The researchers knew that forecasters could us...</td>\n",
       "      <td>8</td>\n",
       "      <td>322</td>\n",
       "      <td>[-0.009542393498122692, 0.012550395913422108, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Colorado not CO However, do not spell out Dist...</td>\n",
       "      <td>8</td>\n",
       "      <td>305</td>\n",
       "      <td>[-0.0038856654427945614, 0.030743436887860298,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  fontsize                                               text  \\\n",
       "0             0       1.0  Common Errors Cheat Sheet Students frequently ...   \n",
       "7             7       1.0  Incorrect: Many red foxes live here. The noctu...   \n",
       "18           18       1.0  so that we can coexist. Incomplete and run on ...   \n",
       "23           23       1.0  Passive: The pasta was eat en by Josephine. Ac...   \n",
       "42           42       1.0  it unclearly; the word could refer to article ...   \n",
       "49           49       1.0  He assured me that the work had been completed...   \n",
       "57           57       1.0  Impact affect, and effect Impact is a percussi...   \n",
       "77           77       1.0  affect versus effect Affect is the verb and ef...   \n",
       "84           84       1.0  Who and that. Use who to refer to a person; us...   \n",
       "91           91       1.0  If you join two complete sentences with a comm...   \n",
       "105         105       1.0  per five pages of text is a good limit; h owev...   \n",
       "126         126       1.0  dash if you type two hyphens in a row, without...   \n",
       "130         130       1.0  Awkward: The sensor measures senescence (veget...   \n",
       "139         139       1.0  around articles ; italicize publications In bo...   \n",
       "158         158       1.0  The researchers knew that forecasters could us...   \n",
       "173         173       1.0  Colorado not CO However, do not spell out Dist...   \n",
       "\n",
       "     page  length                                         embeddings  \n",
       "0       0     314  [-0.007217978592962027, 0.03192491456866264, 0...  \n",
       "7       1     307  [0.016169091686606407, -0.0023459333460778, -0...  \n",
       "18      1     375  [0.005041639320552349, 0.0035730735398828983, ...  \n",
       "23      2     328  [-0.004948729649186134, -0.0033812588080763817...  \n",
       "42      2     352  [0.0018352309707552195, 0.000923340383451432, ...  \n",
       "49      3     307  [0.009392737410962582, -0.010591392405331135, ...  \n",
       "57      4     317  [-0.024574613198637962, 0.0024615300353616476,...  \n",
       "77      4     323  [-0.01929573528468609, 0.009030453860759735, 0...  \n",
       "84      5     309  [-0.00878846738487482, 0.008603863418102264, 0...  \n",
       "91      6     302  [-0.0018168585374951363, 0.0324668250977993, 0...  \n",
       "105     6     325  [-0.015518540516495705, 0.008858335204422474, ...  \n",
       "126     6     326  [-0.008831623941659927, -0.0022563396487385035...  \n",
       "130     7     302  [-0.008791771717369556, -0.005126894451677799,...  \n",
       "139     7     303  [-0.010349431075155735, 0.011574254371225834, ...  \n",
       "158     8     322  [-0.009542393498122692, 0.012550395913422108, ...  \n",
       "173     8     305  [-0.0038856654427945614, 0.030743436887860298,...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search_reviews(df, \"How many swaps can the algorithm make?\", n=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_of_pages = len(pdf.pages)\n",
    "# paper_text = []\n",
    "# for i in range(number_of_pages):\n",
    "#     page = pdf.pages[i]\n",
    "#     page_text = []\n",
    "\n",
    "#     def visitor_body(text, cm, tm, fontDict, fontSize):\n",
    "#         x = tm[4]\n",
    "#         y = tm[5]\n",
    "#         # ignore header/footer\n",
    "#         if (y > 50 and y < 720) and (len(text.strip()) > 1):\n",
    "#             page_text.append({\n",
    "#             'fontsize': fontSize,\n",
    "#             'text': text.strip().replace('\\x03', ''),\n",
    "#             'x': x,\n",
    "#             'y': y\n",
    "#             })\n",
    "\n",
    "#     _ = page.extract_text(visitor_text=visitor_body)\n",
    "\n",
    "#     blob_font_size = None\n",
    "#     blob_text = ''\n",
    "#     processed_text = []\n",
    "\n",
    "#     for t in page_text:\n",
    "#         if t['fontsize'] == blob_font_size:\n",
    "#             blob_text += f\" {t['text']}\"\n",
    "#         else:\n",
    "#             if blob_font_size is not None and len(blob_text) > 1:\n",
    "#                 processed_text.append({\n",
    "#                     'fontsize': blob_font_size,\n",
    "#                     'text': blob_text,\n",
    "#                     'page': i\n",
    "#                 })\n",
    "#             blob_font_size = t['fontsize']\n",
    "#             blob_text = t['text']\n",
    "#         paper_text += processed_text\n",
    "# print(\"Done parsing paper\")\n",
    "\n",
    "# filtered_pdf= []\n",
    "# for row in paper_text:\n",
    "#     if len(row['text']) < 30:\n",
    "#         continue\n",
    "#     filtered_pdf.append(row)\n",
    "# df = pd.DataFrame(filtered_pdf)\n",
    "# # print(df.head())\n",
    "# df['length'] = df['text'].apply(lambda x: len(x))\n",
    "# # print(df.shape)\n",
    "# print('Done creating dataframe')\n",
    "\n",
    "# openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "# embedding_model = \"text-embedding-ada-002\"\n",
    "# print('Calculating embeddings')\n",
    "# print(df.text)\n",
    "# embeddings = df.text.apply([lambda x: get_embedding(x, engine=embedding_model)])\n",
    "# df[\"embeddings\"] = embeddings\n",
    "# print('Done calculating embeddings')\n",
    "# user_input = \"What is GPT-3\"\n",
    "# query_embedding = get_embedding(\n",
    "#     user_input,\n",
    "#     engine=\"text-embedding-ada-002\"\n",
    "# )\n",
    "# df[\"similarity\"] = df.head().embeddings.apply(lambda x: cosine_similarity(x, query_embedding))\n",
    "\n",
    "# results = (\n",
    "#     df.sort_values(\"similarity\", ascending=False)\n",
    "    \n",
    "# )\n",
    "\n",
    "# prompt = \"\"\"You are a large language model whose expertise is reading and summarizing scientific papers. \n",
    "#     You are given a query and a series of text embeddings from a paper in order of their \n",
    "#     cosine similarity to the query. You must take the given embeddings and return a very detailed summary of the paper \n",
    "#     that answers the query.\n",
    "    \n",
    "#     Given the query\"\"\"+ user_input + \"\"\"and the following embeddings: \n",
    "    \n",
    "#     1.\"\"\" + results.iloc[0] + \"\"\"\n",
    "#     2.\"\"\" + results.iloc[1] + \"\"\"\n",
    "#     3.\"\"\" + results.iloc[3] + \"\"\"\n",
    "\n",
    "#     Return a detailed answer based on the paper that answers the query.\"\"\"\n",
    "# print('Generating response from GPT-3')\n",
    "\n",
    "# openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "# r = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=0.4, max_tokens=2000)\n",
    "# response = r.choices[0]['text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def section_headers(corpus):\n",
    "    section_headers = re.findall(r'\\n\\d+\\s+(.*?)\\n', corpus)\n",
    "    filtered_headers = list(filter(lambda x: x[0].isupper() and not x.isnumeric() and len(x.split())<=4, section_headers))\n",
    "    return filtered_headers\n",
    "\n",
    "headers = section_headers(corpus)\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section_texts = re.findall(r'\\n\\d+\\s+(.*?)\\n(.*?)\\n', corpus, re.DOTALL)\n",
    "# section_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex to get paragraphs in between the section headers\n",
    "paragraphs = re.findall(r'\\n\\d+\\s+(.*?)\\n(.*?)\\n\\d+\\s+(.*?)\\n', corpus, re.DOTALL)\n",
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of characters in paragraphs\n",
    "sum([len(i[1]) for i in paragraphs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a large language model whose expertise is reading and summarizing scientific papers. \n",
    "            You are given a query and a series of text embeddings from a paper in order of their \n",
    "            cosine similarity to the query. You must take the given embeddings and return a very detailed summary of the paper \n",
    "            that answers the query.\n",
    "            \n",
    "            Given the query\"\"\"+ query + \"\"\"and the following embeddings: \n",
    "            \n",
    "            1.\"\"\" + embedding1 + \"\"\"\n",
    "            2.\"\"\" + embedding2 + \"\"\"\n",
    "            3.\"\"\" + embedding3 + \"\"\"\n",
    "\n",
    "            Return a detailed answer based on the paper that answers the query.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt(prompt):\n",
    "    openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "    r = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=0.4, max_tokens=2000)\n",
    "    response = r.choices[0]['text']\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = gpt(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(corpus):\n",
    "    prompt = \"\"\"Here is the abstract from a recent machine learning paper:'\"\"\"+corpus+\"\"\"'\n",
    "            Summarize the above content in detail in the style of an excited professor talking about this cool paper he just read.\n",
    "            Summarized content:\"\"\"\n",
    "    summary = gpt(prompt)\n",
    "    summary = summary.replace('\\n', '')\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary = \"I just read an amazing paper on a new machine learning algorithm called Dreamer V three. It's a general and scalable algorithm based on world models, and it outperforms previous approaches across a wide variety of domains. It can handle continuous and discrete actions, visual and low-dimensional inputs, two D and three D worlds, different data budgets, reward frequencies, and reward scales. Plus, it has favorable scaling properties, with larger models resulting in higher data-efficiency and performance. And here's the best part: it's the first algorithm to collect diamonds in Minecraft from scratch without human data or curricula - a long-standing challenge in artificial intelligence. This algorithm makes reinforcement learning broadly applicable and allows scaling to hard decision-making problems. It's really exciting and I can't wait to see what else it can do!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chop(text, chunk_size):\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for word in text.split():\n",
    "        if len(current_chunk) + len(word) + 1 > chunk_size:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = \"\"\n",
    "        current_chunk += word + \" \"\n",
    "    chunks.append(current_chunk)\n",
    "    return chunks\n",
    "\n",
    "chunks = chop(summary, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\"https://mukuls-public-playground.s3.us-east-2.amazonaws.com/jre.mp3\", \"https://mukuls-public-playground.s3.us-east-2.amazonaws.com/jre2.mp3\", \"https://mukuls-public-playground.s3.us-east-2.amazonaws.com/jre3.mp3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast(text, targets):\n",
    "  headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Keep-Alive\": \"timeout=1000, max=100\",\n",
    "  }\n",
    "\n",
    "  data = json.dumps({\n",
    "    \"api_key\": \"ff8f47e8-3643-44bc-b9d3-de51142b95fd\",\n",
    "    \"text\": text,\n",
    "    \"voices\": \"\",\n",
    "    \"target_file\": targets,\n",
    "  })\n",
    "\n",
    "  response = requests.post(\n",
    "    'https://vatsalaggarwal--tts-app.modal.run',\n",
    "    headers=headers,\n",
    "    data=data\n",
    "  )\n",
    "\n",
    "  # Returned audio is 24kHz 32-bit PCM WAV file\n",
    "  # with open('jre3.wav', 'wb') as f:\n",
    "  #     f.write(response.content)\n",
    "  return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate the audio files\n",
    "\n",
    "# from pydub import AudioSegment\n",
    "\n",
    "# def concatenate_audio_files(file_names, output_file_name):\n",
    "#     # Initialize an empty audio segment\n",
    "#     output = AudioSegment.empty()\n",
    "#     # Iterate over the file names\n",
    "#     for file_name in file_names:\n",
    "#         # Load the audio file\n",
    "#         audio = AudioSegment.from_wav(file_name)\n",
    "#         # Concatenate the audio file to the output\n",
    "#         output += audio\n",
    "#     # Save the output to a new file in the folder 'outputs' that is located in the same directory as this notebook\n",
    "#     output.export('outputs/' + output_file_name, format='wav') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Get the file names of the audio files\n",
    "# file_names = ['jre.wav', 'jre2.wav', 'jre3.wav']\n",
    "\n",
    "# concatenate_audio_files(file_names, 'jre_concat.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
