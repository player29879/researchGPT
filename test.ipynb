{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from PyPDF2 import PdfReader\n",
    "import openai\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/2110.01111.pdf\"\n",
    "\n",
    "def get_pdf_object(url):\n",
    "    response = requests.get(arxiv_url)\n",
    "    reader = PdfReader(BytesIO(response.content))\n",
    "    return reader\n",
    "\n",
    "def get_pdf_text(url):\n",
    "    response = requests.get(arxiv_url)\n",
    "    reader = PdfReader(BytesIO(response.content))\n",
    "    corpus = ''\n",
    "    for i in reader.pages:\n",
    "        corpus += i.extract_text()\n",
    "    # remove newlines\n",
    "    # corpus = corpus.replace(\"\\x03\", \"\").replace(\"\\n\", \"\")\n",
    "    return corpus\n",
    "\n",
    "corpus = get_pdf_text(arxiv_url)\n",
    "pdf = get_pdf_object(arxiv_url)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_paper(pdf):\n",
    "  print(\"Parsing paper\")\n",
    "  number_of_pages = len(pdf.pages)\n",
    "  print(f\"Total number of pages: {number_of_pages}\")\n",
    "  paper_text = []\n",
    "  for i in range(number_of_pages):\n",
    "    page = pdf.pages[i]\n",
    "    page_text = []\n",
    "\n",
    "    def visitor_body(text, cm, tm, fontDict, fontSize):\n",
    "      x = tm[4]\n",
    "      y = tm[5]\n",
    "      # ignore header/footer\n",
    "      if (y > 50 and y < 720) and (len(text.strip()) > 1):\n",
    "        page_text.append({\n",
    "          'fontsize': fontSize,\n",
    "          'text': text.strip().replace('\\x03', ''),\n",
    "          'x': x,\n",
    "          'y': y\n",
    "        })\n",
    "\n",
    "    _ = page.extract_text(visitor_text=visitor_body)\n",
    "\n",
    "    blob_font_size = None\n",
    "    blob_text = ''\n",
    "    processed_text = []\n",
    "\n",
    "    for t in page_text:\n",
    "      if t['fontsize'] == blob_font_size:\n",
    "        blob_text += f\" {t['text']}\"\n",
    "      else:\n",
    "        if blob_font_size is not None and len(blob_text) > 1:\n",
    "          processed_text.append({\n",
    "            'fontsize': blob_font_size,\n",
    "            'text': blob_text,\n",
    "            'page': i\n",
    "          })\n",
    "        blob_font_size = t['fontsize']\n",
    "        blob_text = t['text']\n",
    "    paper_text += processed_text\n",
    "  return paper_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = parse_paper(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_df(pdf):\n",
    "    filtered_pdf= []\n",
    "    for row in pdf:\n",
    "        if len(row['text']) < 30:\n",
    "            continue\n",
    "        filtered_pdf.append(row)\n",
    "    df = pd.DataFrame(filtered_pdf)\n",
    "    df['length'] = df['text'].apply(lambda x: len(x))\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = paper_df(paper)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embeddings(df):\n",
    "    embedding_model = \"text-embedding-ada-002\"\n",
    "    embeddings = df.text.apply([lambda x: get_embedding(x, engine=embedding_model)])\n",
    "    df[\"embeddings\"] = embeddings\n",
    "    return df\n",
    "\n",
    "calculate_embeddings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_reviews(df, query, n=3, pprint=True):\n",
    "    query_embedding = get_embedding(\n",
    "        query,\n",
    "        engine=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    df[\"similarity\"] = df.embeddings.apply(lambda x: cosine_similarity(x, query_embedding))\n",
    "\n",
    "    results = (\n",
    "        df.sort_values(\"similarity\", ascending=False, ignore_index=True)\n",
    "        \n",
    "    )\n",
    "    return results.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fontsize</th>\n",
       "      <th>text</th>\n",
       "      <th>page</th>\n",
       "      <th>length</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Common Errors Cheat Sheet Students frequently ...</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>[-0.007276198361068964, 0.03181527554988861, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Incorrect: Many red foxes live here. The noctu...</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>[0.01625715009868145, -0.0023440392687916756, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>so that we can coexist. Incomplete and run on ...</td>\n",
       "      <td>1</td>\n",
       "      <td>375</td>\n",
       "      <td>[0.0050130984745919704, 0.003571423003450036, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Passive: The pasta was eat en by Josephine. Ac...</td>\n",
       "      <td>2</td>\n",
       "      <td>328</td>\n",
       "      <td>[-0.004926593974232674, -0.0034326203167438507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>it unclearly; the word could refer to article ...</td>\n",
       "      <td>2</td>\n",
       "      <td>352</td>\n",
       "      <td>[0.0018352309707552195, 0.000923340383451432, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  fontsize                                               text  \\\n",
       "0           0       1.0  Common Errors Cheat Sheet Students frequently ...   \n",
       "1           7       1.0  Incorrect: Many red foxes live here. The noctu...   \n",
       "2          18       1.0  so that we can coexist. Incomplete and run on ...   \n",
       "3          23       1.0  Passive: The pasta was eat en by Josephine. Ac...   \n",
       "4          42       1.0  it unclearly; the word could refer to article ...   \n",
       "\n",
       "   page  length                                         embeddings  \n",
       "0     0     314  [-0.007276198361068964, 0.03181527554988861, 0...  \n",
       "1     1     307  [0.01625715009868145, -0.0023440392687916756, ...  \n",
       "2     1     375  [0.0050130984745919704, 0.003571423003450036, ...  \n",
       "3     2     328  [-0.004926593974232674, -0.0034326203167438507...  \n",
       "4     2     352  [0.0018352309707552195, 0.000923340383451432, ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"embeddings.csv\")\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = test.drop_duplicates(subset=['text', 'page'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fontsize</th>\n",
       "      <th>text</th>\n",
       "      <th>page</th>\n",
       "      <th>length</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Common Errors Cheat Sheet Students frequently ...</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>[-0.007217978592962027, 0.03192491456866264, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Incorrect: Many red foxes live here. The noctu...</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>[0.016169091686606407, -0.0023459333460778, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>so that we can coexist. Incomplete and run on ...</td>\n",
       "      <td>1</td>\n",
       "      <td>375</td>\n",
       "      <td>[0.005041639320552349, 0.0035730735398828983, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Passive: The pasta was eat en by Josephine. Ac...</td>\n",
       "      <td>2</td>\n",
       "      <td>328</td>\n",
       "      <td>[-0.004948729649186134, -0.0033812588080763817...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>it unclearly; the word could refer to article ...</td>\n",
       "      <td>2</td>\n",
       "      <td>352</td>\n",
       "      <td>[0.0018352309707552195, 0.000923340383451432, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>He assured me that the work had been completed...</td>\n",
       "      <td>3</td>\n",
       "      <td>307</td>\n",
       "      <td>[0.009392737410962582, -0.010591392405331135, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Impact affect, and effect Impact is a percussi...</td>\n",
       "      <td>4</td>\n",
       "      <td>317</td>\n",
       "      <td>[-0.024574613198637962, 0.0024615300353616476,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>affect versus effect Affect is the verb and ef...</td>\n",
       "      <td>4</td>\n",
       "      <td>323</td>\n",
       "      <td>[-0.01929573528468609, 0.009030453860759735, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Who and that. Use who to refer to a person; us...</td>\n",
       "      <td>5</td>\n",
       "      <td>309</td>\n",
       "      <td>[-0.00878846738487482, 0.008603863418102264, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>If you join two complete sentences with a comm...</td>\n",
       "      <td>6</td>\n",
       "      <td>302</td>\n",
       "      <td>[-0.0018168585374951363, 0.0324668250977993, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>per five pages of text is a good limit; h owev...</td>\n",
       "      <td>6</td>\n",
       "      <td>325</td>\n",
       "      <td>[-0.015518540516495705, 0.008858335204422474, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dash if you type two hyphens in a row, without...</td>\n",
       "      <td>6</td>\n",
       "      <td>326</td>\n",
       "      <td>[-0.008831623941659927, -0.0022563396487385035...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Awkward: The sensor measures senescence (veget...</td>\n",
       "      <td>7</td>\n",
       "      <td>302</td>\n",
       "      <td>[-0.008791771717369556, -0.005126894451677799,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>around articles ; italicize publications In bo...</td>\n",
       "      <td>7</td>\n",
       "      <td>303</td>\n",
       "      <td>[-0.010349431075155735, 0.011574254371225834, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The researchers knew that forecasters could us...</td>\n",
       "      <td>8</td>\n",
       "      <td>322</td>\n",
       "      <td>[-0.009542393498122692, 0.012550395913422108, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Colorado not CO However, do not spell out Dist...</td>\n",
       "      <td>8</td>\n",
       "      <td>305</td>\n",
       "      <td>[-0.0038856654427945614, 0.030743436887860298,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  fontsize                                               text  \\\n",
       "0             0       1.0  Common Errors Cheat Sheet Students frequently ...   \n",
       "7             7       1.0  Incorrect: Many red foxes live here. The noctu...   \n",
       "18           18       1.0  so that we can coexist. Incomplete and run on ...   \n",
       "23           23       1.0  Passive: The pasta was eat en by Josephine. Ac...   \n",
       "42           42       1.0  it unclearly; the word could refer to article ...   \n",
       "49           49       1.0  He assured me that the work had been completed...   \n",
       "57           57       1.0  Impact affect, and effect Impact is a percussi...   \n",
       "77           77       1.0  affect versus effect Affect is the verb and ef...   \n",
       "84           84       1.0  Who and that. Use who to refer to a person; us...   \n",
       "91           91       1.0  If you join two complete sentences with a comm...   \n",
       "105         105       1.0  per five pages of text is a good limit; h owev...   \n",
       "126         126       1.0  dash if you type two hyphens in a row, without...   \n",
       "130         130       1.0  Awkward: The sensor measures senescence (veget...   \n",
       "139         139       1.0  around articles ; italicize publications In bo...   \n",
       "158         158       1.0  The researchers knew that forecasters could us...   \n",
       "173         173       1.0  Colorado not CO However, do not spell out Dist...   \n",
       "\n",
       "     page  length                                         embeddings  \n",
       "0       0     314  [-0.007217978592962027, 0.03192491456866264, 0...  \n",
       "7       1     307  [0.016169091686606407, -0.0023459333460778, -0...  \n",
       "18      1     375  [0.005041639320552349, 0.0035730735398828983, ...  \n",
       "23      2     328  [-0.004948729649186134, -0.0033812588080763817...  \n",
       "42      2     352  [0.0018352309707552195, 0.000923340383451432, ...  \n",
       "49      3     307  [0.009392737410962582, -0.010591392405331135, ...  \n",
       "57      4     317  [-0.024574613198637962, 0.0024615300353616476,...  \n",
       "77      4     323  [-0.01929573528468609, 0.009030453860759735, 0...  \n",
       "84      5     309  [-0.00878846738487482, 0.008603863418102264, 0...  \n",
       "91      6     302  [-0.0018168585374951363, 0.0324668250977993, 0...  \n",
       "105     6     325  [-0.015518540516495705, 0.008858335204422474, ...  \n",
       "126     6     326  [-0.008831623941659927, -0.0022563396487385035...  \n",
       "130     7     302  [-0.008791771717369556, -0.005126894451677799,...  \n",
       "139     7     303  [-0.010349431075155735, 0.011574254371225834, ...  \n",
       "158     8     322  [-0.009542393498122692, 0.012550395913422108, ...  \n",
       "173     8     305  [-0.0038856654427945614, 0.030743436887860298,...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search_reviews(df, \"How many swaps can the algorithm make?\", n=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_of_pages = len(pdf.pages)\n",
    "# paper_text = []\n",
    "# for i in range(number_of_pages):\n",
    "#     page = pdf.pages[i]\n",
    "#     page_text = []\n",
    "\n",
    "#     def visitor_body(text, cm, tm, fontDict, fontSize):\n",
    "#         x = tm[4]\n",
    "#         y = tm[5]\n",
    "#         # ignore header/footer\n",
    "#         if (y > 50 and y < 720) and (len(text.strip()) > 1):\n",
    "#             page_text.append({\n",
    "#             'fontsize': fontSize,\n",
    "#             'text': text.strip().replace('\\x03', ''),\n",
    "#             'x': x,\n",
    "#             'y': y\n",
    "#             })\n",
    "\n",
    "#     _ = page.extract_text(visitor_text=visitor_body)\n",
    "\n",
    "#     blob_font_size = None\n",
    "#     blob_text = ''\n",
    "#     processed_text = []\n",
    "\n",
    "#     for t in page_text:\n",
    "#         if t['fontsize'] == blob_font_size:\n",
    "#             blob_text += f\" {t['text']}\"\n",
    "#         else:\n",
    "#             if blob_font_size is not None and len(blob_text) > 1:\n",
    "#                 processed_text.append({\n",
    "#                     'fontsize': blob_font_size,\n",
    "#                     'text': blob_text,\n",
    "#                     'page': i\n",
    "#                 })\n",
    "#             blob_font_size = t['fontsize']\n",
    "#             blob_text = t['text']\n",
    "#         paper_text += processed_text\n",
    "# print(\"Done parsing paper\")\n",
    "\n",
    "# filtered_pdf= []\n",
    "# for row in paper_text:\n",
    "#     if len(row['text']) < 30:\n",
    "#         continue\n",
    "#     filtered_pdf.append(row)\n",
    "# df = pd.DataFrame(filtered_pdf)\n",
    "# # print(df.head())\n",
    "# df['length'] = df['text'].apply(lambda x: len(x))\n",
    "# # print(df.shape)\n",
    "# print('Done creating dataframe')\n",
    "\n",
    "# openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "# embedding_model = \"text-embedding-ada-002\"\n",
    "# print('Calculating embeddings')\n",
    "# print(df.text)\n",
    "# embeddings = df.text.apply([lambda x: get_embedding(x, engine=embedding_model)])\n",
    "# df[\"embeddings\"] = embeddings\n",
    "# print('Done calculating embeddings')\n",
    "# user_input = \"What is GPT-3\"\n",
    "# query_embedding = get_embedding(\n",
    "#     user_input,\n",
    "#     engine=\"text-embedding-ada-002\"\n",
    "# )\n",
    "# df[\"similarity\"] = df.head().embeddings.apply(lambda x: cosine_similarity(x, query_embedding))\n",
    "\n",
    "# results = (\n",
    "#     df.sort_values(\"similarity\", ascending=False)\n",
    "    \n",
    "# )\n",
    "\n",
    "# prompt = \"\"\"You are a large language model whose expertise is reading and summarizing scientific papers. \n",
    "#     You are given a query and a series of text embeddings from a paper in order of their \n",
    "#     cosine similarity to the query. You must take the given embeddings and return a very detailed summary of the paper \n",
    "#     that answers the query.\n",
    "    \n",
    "#     Given the query\"\"\"+ user_input + \"\"\"and the following embeddings: \n",
    "    \n",
    "#     1.\"\"\" + results.iloc[0] + \"\"\"\n",
    "#     2.\"\"\" + results.iloc[1] + \"\"\"\n",
    "#     3.\"\"\" + results.iloc[3] + \"\"\"\n",
    "\n",
    "#     Return a detailed answer based on the paper that answers the query.\"\"\"\n",
    "# print('Generating response from GPT-3')\n",
    "\n",
    "# openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "# r = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=0.4, max_tokens=2000)\n",
    "# response = r.choices[0]['text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def section_headers(corpus):\n",
    "    section_headers = re.findall(r'\\n\\d+\\s+(.*?)\\n', corpus)\n",
    "    filtered_headers = list(filter(lambda x: x[0].isupper() and not x.isnumeric() and len(x.split())<=4, section_headers))\n",
    "    return filtered_headers\n",
    "\n",
    "headers = section_headers(corpus)\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section_texts = re.findall(r'\\n\\d+\\s+(.*?)\\n(.*?)\\n', corpus, re.DOTALL)\n",
    "# section_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex to get paragraphs in between the section headers\n",
    "paragraphs = re.findall(r'\\n\\d+\\s+(.*?)\\n(.*?)\\n\\d+\\s+(.*?)\\n', corpus, re.DOTALL)\n",
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of characters in paragraphs\n",
    "sum([len(i[1]) for i in paragraphs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a large language model whose expertise is reading and summarizing scientific papers. \n",
    "            You are given a query and a series of text embeddings from a paper in order of their \n",
    "            cosine similarity to the query. You must take the given embeddings and return a very detailed summary of the paper \n",
    "            that answers the query.\n",
    "            \n",
    "            Given the query\"\"\"+ query + \"\"\"and the following embeddings: \n",
    "            \n",
    "            1.\"\"\" + embedding1 + \"\"\"\n",
    "            2.\"\"\" + embedding2 + \"\"\"\n",
    "            3.\"\"\" + embedding3 + \"\"\"\n",
    "\n",
    "            Return a detailed answer based on the paper that answers the query.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt(prompt):\n",
    "    openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "    r = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=0.4, max_tokens=2000)\n",
    "    response = r.choices[0]['text']\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = gpt(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(corpus):\n",
    "    prompt = \"\"\"Here is the abstract from a recent machine learning paper:'\"\"\"+corpus+\"\"\"'\n",
    "            Summarize the above content in detail in the style of an excited professor talking about this cool paper he just read.\n",
    "            Summarized content:\"\"\"\n",
    "    summary = gpt(prompt)\n",
    "    summary = summary.replace('\\n', '')\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary = \"I just read an amazing paper on a new machine learning algorithm called Dreamer V three. It's a general and scalable algorithm based on world models, and it outperforms previous approaches across a wide variety of domains. It can handle continuous and discrete actions, visual and low-dimensional inputs, two D and three D worlds, different data budgets, reward frequencies, and reward scales. Plus, it has favorable scaling properties, with larger models resulting in higher data-efficiency and performance. And here's the best part: it's the first algorithm to collect diamonds in Minecraft from scratch without human data or curricula - a long-standing challenge in artificial intelligence. This algorithm makes reinforcement learning broadly applicable and allows scaling to hard decision-making problems. It's really exciting and I can't wait to see what else it can do!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chop(text, chunk_size):\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for word in text.split():\n",
    "        if len(current_chunk) + len(word) + 1 > chunk_size:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = \"\"\n",
    "        current_chunk += word + \" \"\n",
    "    chunks.append(current_chunk)\n",
    "    return chunks\n",
    "\n",
    "chunks = chop(summary, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\"https://mukuls-public-playground.s3.us-east-2.amazonaws.com/jre.mp3\", \"https://mukuls-public-playground.s3.us-east-2.amazonaws.com/jre2.mp3\", \"https://mukuls-public-playground.s3.us-east-2.amazonaws.com/jre3.mp3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast(text, targets):\n",
    "  headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Keep-Alive\": \"timeout=1000, max=100\",\n",
    "  }\n",
    "\n",
    "  data = json.dumps({\n",
    "    \"api_key\": \"ff8f47e8-3643-44bc-b9d3-de51142b95fd\",\n",
    "    \"text\": text,\n",
    "    \"voices\": \"\",\n",
    "    \"target_file\": targets,\n",
    "  })\n",
    "\n",
    "  response = requests.post(\n",
    "    'https://vatsalaggarwal--tts-app.modal.run',\n",
    "    headers=headers,\n",
    "    data=data\n",
    "  )\n",
    "\n",
    "  # Returned audio is 24kHz 32-bit PCM WAV file\n",
    "  # with open('jre3.wav', 'wb') as f:\n",
    "  #     f.write(response.content)\n",
    "  return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate the audio files\n",
    "\n",
    "# from pydub import AudioSegment\n",
    "\n",
    "# def concatenate_audio_files(file_names, output_file_name):\n",
    "#     # Initialize an empty audio segment\n",
    "#     output = AudioSegment.empty()\n",
    "#     # Iterate over the file names\n",
    "#     for file_name in file_names:\n",
    "#         # Load the audio file\n",
    "#         audio = AudioSegment.from_wav(file_name)\n",
    "#         # Concatenate the audio file to the output\n",
    "#         output += audio\n",
    "#     # Save the output to a new file in the folder 'outputs' that is located in the same directory as this notebook\n",
    "#     output.export('outputs/' + output_file_name, format='wav') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Get the file names of the audio files\n",
    "# file_names = ['jre.wav', 'jre2.wav', 'jre3.wav']\n",
    "\n",
    "# concatenate_audio_files(file_names, 'jre_concat.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
