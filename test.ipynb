{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from PyPDF2 import PdfReader\n",
    "import openai\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/2110.01111.pdf\"\n",
    "\n",
    "def get_pdf_object(url):\n",
    "    response = requests.get(arxiv_url)\n",
    "    reader = PdfReader(BytesIO(response.content))\n",
    "    return reader\n",
    "\n",
    "def get_pdf_text(url):\n",
    "    response = requests.get(arxiv_url)\n",
    "    reader = PdfReader(BytesIO(response.content))\n",
    "    corpus = ''\n",
    "    for i in reader.pages:\n",
    "        corpus += i.extract_text()\n",
    "    # remove newlines\n",
    "    # corpus = corpus.replace(\"\\x03\", \"\").replace(\"\\n\", \"\")\n",
    "    return corpus\n",
    "\n",
    "corpus = get_pdf_text(arxiv_url)\n",
    "pdf = get_pdf_object(arxiv_url)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_paper(pdf):\n",
    "  print(\"Parsing paper\")\n",
    "  number_of_pages = len(pdf.pages)\n",
    "  print(f\"Total number of pages: {number_of_pages}\")\n",
    "  paper_text = []\n",
    "  for i in range(number_of_pages):\n",
    "    page = pdf.pages[i]\n",
    "    page_text = []\n",
    "\n",
    "    def visitor_body(text, cm, tm, fontDict, fontSize):\n",
    "      x = tm[4]\n",
    "      y = tm[5]\n",
    "      # ignore header/footer\n",
    "      if (y > 50 and y < 720) and (len(text.strip()) > 1):\n",
    "        page_text.append({\n",
    "          'fontsize': fontSize,\n",
    "          'text': text.strip().replace('\\x03', ''),\n",
    "          'x': x,\n",
    "          'y': y\n",
    "        })\n",
    "\n",
    "    _ = page.extract_text(visitor_text=visitor_body)\n",
    "\n",
    "    blob_font_size = None\n",
    "    blob_text = ''\n",
    "    processed_text = []\n",
    "\n",
    "    for t in page_text:\n",
    "      if t['fontsize'] == blob_font_size:\n",
    "        blob_text += f\" {t['text']}\"\n",
    "      else:\n",
    "        if blob_font_size is not None and len(blob_text) > 1:\n",
    "          processed_text.append({\n",
    "            'fontsize': blob_font_size,\n",
    "            'text': blob_text,\n",
    "            'page': i\n",
    "          })\n",
    "        blob_font_size = t['fontsize']\n",
    "        blob_text = t['text']\n",
    "    paper_text += processed_text\n",
    "  return paper_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = parse_paper(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_df(pdf):\n",
    "    filtered_pdf= []\n",
    "    for row in pdf:\n",
    "        if len(row['text']) < 30:\n",
    "            continue\n",
    "        filtered_pdf.append(row)\n",
    "    df = pd.DataFrame(filtered_pdf)\n",
    "    df['length'] = df['text'].apply(lambda x: len(x))\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = paper_df(paper)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embeddings(df):\n",
    "    embedding_model = \"text-embedding-ada-002\"\n",
    "    embeddings = df.text.apply([lambda x: get_embedding(x, engine=embedding_model)])\n",
    "    df[\"embeddings\"] = embeddings\n",
    "    return df\n",
    "\n",
    "calculate_embeddings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_reviews(df, query, n=3, pprint=True):\n",
    "    query_embedding = get_embedding(\n",
    "        query,\n",
    "        engine=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    df[\"similarity\"] = df.embeddings.apply(lambda x: cosine_similarity(x, query_embedding))\n",
    "\n",
    "    results = (\n",
    "        df.sort_values(\"similarity\", ascending=False, ignore_index=True)\n",
    "        \n",
    "    )\n",
    "    return results.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search_reviews(df, \"How many swaps can the algorithm make?\", n=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_of_pages = len(pdf.pages)\n",
    "# paper_text = []\n",
    "# for i in range(number_of_pages):\n",
    "#     page = pdf.pages[i]\n",
    "#     page_text = []\n",
    "\n",
    "#     def visitor_body(text, cm, tm, fontDict, fontSize):\n",
    "#         x = tm[4]\n",
    "#         y = tm[5]\n",
    "#         # ignore header/footer\n",
    "#         if (y > 50 and y < 720) and (len(text.strip()) > 1):\n",
    "#             page_text.append({\n",
    "#             'fontsize': fontSize,\n",
    "#             'text': text.strip().replace('\\x03', ''),\n",
    "#             'x': x,\n",
    "#             'y': y\n",
    "#             })\n",
    "\n",
    "#     _ = page.extract_text(visitor_text=visitor_body)\n",
    "\n",
    "#     blob_font_size = None\n",
    "#     blob_text = ''\n",
    "#     processed_text = []\n",
    "\n",
    "#     for t in page_text:\n",
    "#         if t['fontsize'] == blob_font_size:\n",
    "#             blob_text += f\" {t['text']}\"\n",
    "#         else:\n",
    "#             if blob_font_size is not None and len(blob_text) > 1:\n",
    "#                 processed_text.append({\n",
    "#                     'fontsize': blob_font_size,\n",
    "#                     'text': blob_text,\n",
    "#                     'page': i\n",
    "#                 })\n",
    "#             blob_font_size = t['fontsize']\n",
    "#             blob_text = t['text']\n",
    "#         paper_text += processed_text\n",
    "# print(\"Done parsing paper\")\n",
    "\n",
    "# filtered_pdf= []\n",
    "# for row in paper_text:\n",
    "#     if len(row['text']) < 30:\n",
    "#         continue\n",
    "#     filtered_pdf.append(row)\n",
    "# df = pd.DataFrame(filtered_pdf)\n",
    "# # print(df.head())\n",
    "# df['length'] = df['text'].apply(lambda x: len(x))\n",
    "# # print(df.shape)\n",
    "# print('Done creating dataframe')\n",
    "\n",
    "# openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "# embedding_model = \"text-embedding-ada-002\"\n",
    "# print('Calculating embeddings')\n",
    "# print(df.text)\n",
    "# embeddings = df.text.apply([lambda x: get_embedding(x, engine=embedding_model)])\n",
    "# df[\"embeddings\"] = embeddings\n",
    "# print('Done calculating embeddings')\n",
    "# user_input = \"What is GPT-3\"\n",
    "# query_embedding = get_embedding(\n",
    "#     user_input,\n",
    "#     engine=\"text-embedding-ada-002\"\n",
    "# )\n",
    "# df[\"similarity\"] = df.head().embeddings.apply(lambda x: cosine_similarity(x, query_embedding))\n",
    "\n",
    "# results = (\n",
    "#     df.sort_values(\"similarity\", ascending=False)\n",
    "    \n",
    "# )\n",
    "\n",
    "# prompt = \"\"\"You are a large language model whose expertise is reading and summarizing scientific papers. \n",
    "#     You are given a query and a series of text embeddings from a paper in order of their \n",
    "#     cosine similarity to the query. You must take the given embeddings and return a very detailed summary of the paper \n",
    "#     that answers the query.\n",
    "    \n",
    "#     Given the query\"\"\"+ user_input + \"\"\"and the following embeddings: \n",
    "    \n",
    "#     1.\"\"\" + results.iloc[0] + \"\"\"\n",
    "#     2.\"\"\" + results.iloc[1] + \"\"\"\n",
    "#     3.\"\"\" + results.iloc[3] + \"\"\"\n",
    "\n",
    "#     Return a detailed answer based on the paper that answers the query.\"\"\"\n",
    "# print('Generating response from GPT-3')\n",
    "\n",
    "# openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "# r = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=0.4, max_tokens=2000)\n",
    "# response = r.choices[0]['text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def section_headers(corpus):\n",
    "    section_headers = re.findall(r'\\n\\d+\\s+(.*?)\\n', corpus)\n",
    "    filtered_headers = list(filter(lambda x: x[0].isupper() and not x.isnumeric() and len(x.split())<=4, section_headers))\n",
    "    return filtered_headers\n",
    "\n",
    "headers = section_headers(corpus)\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section_texts = re.findall(r'\\n\\d+\\s+(.*?)\\n(.*?)\\n', corpus, re.DOTALL)\n",
    "# section_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex to get paragraphs in between the section headers\n",
    "paragraphs = re.findall(r'\\n\\d+\\s+(.*?)\\n(.*?)\\n\\d+\\s+(.*?)\\n', corpus, re.DOTALL)\n",
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of characters in paragraphs\n",
    "sum([len(i[1]) for i in paragraphs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a large language model whose expertise is reading and summarizing scientific papers. \n",
    "            You are given a query and a series of text embeddings from a paper in order of their \n",
    "            cosine similarity to the query. You must take the given embeddings and return a very detailed summary of the paper \n",
    "            that answers the query.\n",
    "            \n",
    "            Given the query\"\"\"+ query + \"\"\"and the following embeddings: \n",
    "            \n",
    "            1.\"\"\" + embedding1 + \"\"\"\n",
    "            2.\"\"\" + embedding2 + \"\"\"\n",
    "            3.\"\"\" + embedding3 + \"\"\"\n",
    "\n",
    "            Return a detailed answer based on the paper that answers the query.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt(prompt):\n",
    "    openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "    r = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=0.4, max_tokens=2000)\n",
    "    response = r.choices[0]['text']\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = gpt(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(corpus):\n",
    "    prompt = \"\"\"Here is the abstract from a recent machine learning paper:'\"\"\"+corpus+\"\"\"'\n",
    "            Summarize the above content in detail in the style of an excited professor talking about this cool paper he just read.\n",
    "            Summarized content:\"\"\"\n",
    "    summary = gpt(prompt)\n",
    "    summary = summary.replace('\\n', '')\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary = \"I just read an amazing paper on a new machine learning algorithm called Dreamer V three. It's a general and scalable algorithm based on world models, and it outperforms previous approaches across a wide variety of domains. It can handle continuous and discrete actions, visual and low-dimensional inputs, two D and three D worlds, different data budgets, reward frequencies, and reward scales. Plus, it has favorable scaling properties, with larger models resulting in higher data-efficiency and performance. And here's the best part: it's the first algorithm to collect diamonds in Minecraft from scratch without human data or curricula - a long-standing challenge in artificial intelligence. This algorithm makes reinforcement learning broadly applicable and allows scaling to hard decision-making problems. It's really exciting and I can't wait to see what else it can do!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chop(text, chunk_size):\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for word in text.split():\n",
    "        if len(current_chunk) + len(word) + 1 > chunk_size:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = \"\"\n",
    "        current_chunk += word + \" \"\n",
    "    chunks.append(current_chunk)\n",
    "    return chunks\n",
    "\n",
    "chunks = chop(summary, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\"https://mukuls-public-playground.s3.us-east-2.amazonaws.com/jre.mp3\", \"https://mukuls-public-playground.s3.us-east-2.amazonaws.com/jre2.mp3\", \"https://mukuls-public-playground.s3.us-east-2.amazonaws.com/jre3.mp3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast(text, targets):\n",
    "  headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Keep-Alive\": \"timeout=1000, max=100\",\n",
    "  }\n",
    "\n",
    "  data = json.dumps({\n",
    "    \"api_key\": \"ff8f47e8-3643-44bc-b9d3-de51142b95fd\",\n",
    "    \"text\": text,\n",
    "    \"voices\": \"\",\n",
    "    \"target_file\": targets,\n",
    "  })\n",
    "\n",
    "  response = requests.post(\n",
    "    'https://vatsalaggarwal--tts-app.modal.run',\n",
    "    headers=headers,\n",
    "    data=data\n",
    "  )\n",
    "\n",
    "  # Returned audio is 24kHz 32-bit PCM WAV file\n",
    "  # with open('jre3.wav', 'wb') as f:\n",
    "  #     f.write(response.content)\n",
    "  return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate the audio files\n",
    "\n",
    "# from pydub import AudioSegment\n",
    "\n",
    "# def concatenate_audio_files(file_names, output_file_name):\n",
    "#     # Initialize an empty audio segment\n",
    "#     output = AudioSegment.empty()\n",
    "#     # Iterate over the file names\n",
    "#     for file_name in file_names:\n",
    "#         # Load the audio file\n",
    "#         audio = AudioSegment.from_wav(file_name)\n",
    "#         # Concatenate the audio file to the output\n",
    "#         output += audio\n",
    "#     # Save the output to a new file in the folder 'outputs' that is located in the same directory as this notebook\n",
    "#     output.export('outputs/' + output_file_name, format='wav') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Get the file names of the audio files\n",
    "# file_names = ['jre.wav', 'jre2.wav', 'jre3.wav']\n",
    "\n",
    "# concatenate_audio_files(file_names, 'jre_concat.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 10:17:43) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
